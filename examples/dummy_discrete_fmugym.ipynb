{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225772d6",
   "metadata": {},
   "source": [
    "# Discrete dummy example for gym environment with FMU with HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11deb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from fmpy import read_model_description, extract\n",
    "\n",
    "from fmugym import FMUGym, FMUGymConfig, VarSpace, State2Out, TargetValue\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7385ea-4589-4a1f-884d-8fb335134f50",
   "metadata": {},
   "source": [
    "### Parameters of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca189da-c534-4e14-8498-06e98b21b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMUEnv(FMUGym):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.processed_action = None\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {'info_time':time.time()}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \n",
    "        self._get_fmu_output()\n",
    "\n",
    "        obs = np.array(list(self.observation.values())).flatten()\n",
    "        \n",
    "        noisy_observation = obs + self._get_output_noise()\n",
    "        # suspected problem with SB3, the addition of the start offset shouldn't be necessary, \n",
    "        # when sampling from the action space manually there is no such problem\n",
    "        noisy_observation = np.round(noisy_observation/config.disc_resol_obs, 0) * config.disc_resol_obs\n",
    "        \n",
    "        setpoint = self.setpoint_trajectory(self.y_start, self.y_stop, self.time)\n",
    "        setpoint = np.round(setpoint/config.disc_resol_obs, 0) * config.disc_resol_obs\n",
    "        \n",
    "        obs_dict = OrderedDict([\n",
    "            ('observation', noisy_observation),\n",
    "            ('achieved_goal', noisy_observation),\n",
    "            ('desired_goal', setpoint.astype(np.float32))\n",
    "        ])\n",
    "        return obs_dict\n",
    "    \n",
    "    def _get_input_noise(self):\n",
    "        input_noise = []\n",
    "        for inp_name in self.input_dict:\n",
    "            input_noise.append(self.input_noise[inp_name].sample()[0])\n",
    "        return np.array(input_noise)\n",
    "\n",
    "    def _get_output_noise(self):\n",
    "        output_noise = []\n",
    "        for out_name in self.output_dict:\n",
    "                output_noise.append(self.output_noise[out_name].sample()[0])\n",
    "        return np.array(output_noise)\n",
    "\n",
    "    def _get_terminated(self):\n",
    "        if self.time > self.stop_time:\n",
    "            self.reset()\n",
    "            return True, False\n",
    "\n",
    "        for termination in self.terminations:\n",
    "            min_value = self.terminations[termination].low[0]\n",
    "            max_value = self.terminations[termination].high[0]\n",
    "            if self.observation[termination] < min_value or self.observation[termination] > max_value:\n",
    "                self.reset()\n",
    "                return False, True\n",
    "\n",
    "        return False, False\n",
    "\n",
    "    def _create_action_space(self, inputs):\n",
    "        lows = []\n",
    "        lens = []\n",
    "        for inp in inputs:\n",
    "            lows.append(inputs[inp].start)\n",
    "            lens.append(inputs[inp].n)\n",
    "        action_space = gym.spaces.MultiDiscrete(np.array(lens), start=np.array(lows))\n",
    "        return action_space\n",
    "    \n",
    "    def _create_observation_space(self, outputs):\n",
    "        lows = []\n",
    "        highs = []\n",
    "        for out in outputs:\n",
    "            lows.append(config.disc_resol_obs * outputs[out].start)\n",
    "            highs.append(config.disc_resol_obs * (outputs[out].start + outputs[out].n))\n",
    "        # no MuliDiscrete implementation of obs space even if values are discretized by rounding in _get_obs()\n",
    "        # as SB3 is suspected to not handle MuliDiscrete for obs properly (no convergence in tests)\n",
    "        observation_space = gym.spaces.Dict({\n",
    "            'observation': gym.spaces.Box(low=np.array(lows), high=np.array(highs), dtype=np.float32),\n",
    "            'achieved_goal': gym.spaces.Box(low=np.array(lows), high=np.array(highs), dtype=np.float32),\n",
    "            'desired_goal': gym.spaces.Box(low=np.array(lows), high=np.array(highs), dtype=np.float32)\n",
    "        })\n",
    "        return observation_space\n",
    "\n",
    "    def _noisy_init(self):\n",
    "        # add noise to setpoint goals\n",
    "        for ye in self.y_stop:\n",
    "            self.y_stop[ye] = self.y_stop_range[ye].sample()[0]\n",
    "        \n",
    "        # add noise to initial system state\n",
    "        init_states = {}\n",
    "        for var in self.random_vars_refs:\n",
    "            var_ref = self.random_vars_refs[var][0]\n",
    "            uniform_value = self.random_vars_refs[var][1].sample()[0]\n",
    "            init_states[var_ref] = uniform_value\n",
    "\n",
    "            # domain randomization with noisy initial y_start\n",
    "            if var in self.rand_starts.keys():\n",
    "                input_string = self.rand_starts[var]\n",
    "                self.y_start[input_string] = float(uniform_value)\n",
    "        \n",
    "        return init_states\n",
    "\n",
    "    def _process_action(self, action):\n",
    "        # scale action to [-2, 2] the addition of the start offset shouldn't be necessary, \n",
    "        # when sampling from the action space manually there is no such problem\n",
    "        scaled_action = config.disc_resol_act*(action + self.action_space.start) \n",
    "        self.processed_action = scaled_action + self._get_input_noise()\n",
    "        return self.processed_action\n",
    "\n",
    "    def setpoint_trajectory(self, y_start, y_stop, time):\n",
    "        y = []\n",
    "        for y0, ye in zip(y_start.values(), y_stop.values()):\n",
    "            y.append((ye - y0)/(self.stop_time-self.start_time)*(time-self.start_time) + y0)\n",
    "        return np.array(y)\n",
    "\n",
    "    def _process_reward(self, obs, acts, info):\n",
    "        achieved_goal = obs[\"achieved_goal\"]\n",
    "        desired_goal = obs[\"desired_goal\"]\n",
    "        reward = self.compute_reward(achieved_goal, desired_goal, info)\n",
    "        return reward\n",
    "    \n",
    "    def compute_reward(self, achieved_goal, desired_goal, info):\n",
    "        \"\"\"\n",
    "        compute reward for HER\n",
    "            achieved_goal: outputs of FMU\n",
    "            desired_goal: current setpoint of trajectory\n",
    "            info: [NOT USED]\n",
    "        Returns:\n",
    "            float: environment reward\n",
    "        \"\"\"\n",
    "        control_error = achieved_goal - desired_goal\n",
    "        reward = - np.sum(control_error**2)\n",
    "        \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e20963-cfc0-4e45-8d6e-f8df2f1c3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = VarSpace(\"inputs\")\n",
    "inputs.add_var_discrete(\"input1\", 41, -20)\n",
    "inputs.add_var_discrete(\"input2\", 41, -20)\n",
    "\n",
    "input_noise = VarSpace(\"input_noise\")\n",
    "input_noise.add_var_box(\"input1\", 0.0, 0.0)\n",
    "input_noise.add_var_box(\"input2\", 0.0, 0.0)\n",
    "\n",
    "outputs = VarSpace(\"outputs\")\n",
    "outputs.add_var_discrete(\"output1\", 4001, -2000)\n",
    "outputs.add_var_discrete(\"output2\", 4001, -2000)\n",
    "\n",
    "output_noise = VarSpace(\"output_noise\")\n",
    "output_noise.add_var_box(\"output1\", 0.0, 0.0)\n",
    "output_noise.add_var_box(\"output2\", 0.0, 0.0)\n",
    "\n",
    "# dynamics and domain randomization\n",
    "random_vars = VarSpace(\"random_vars\")\n",
    "random_vars.add_var_box(\"firstOrder.k\", 4, 6)\n",
    "random_vars.add_var_box(\"firstOrder1.k\", 4, 6)\n",
    "random_vars.add_var_box(\"firstOrder.y_start\", -0.5, 0.5)\n",
    "random_vars.add_var_box(\"firstOrder1.y_start\", -0.5, 0.5)\n",
    "\n",
    "# map state variables to corresponding outputs of Modelica Model\n",
    "set_point_map = State2Out(\"set_point_map\")\n",
    "set_point_map.add_map(\"firstOrder.y_start\", \"output1\")\n",
    "set_point_map.add_map(\"firstOrder1.y_start\", \"output2\")\n",
    "\n",
    "set_point_nominal_start = TargetValue(\"set_point_nominal_start\")\n",
    "set_point_nominal_start.add_target(\"output1\", 0.0)\n",
    "set_point_nominal_start.add_target(\"output2\", 0.0)\n",
    "\n",
    "set_point_stop = VarSpace(\"set_point_stop\")\n",
    "set_point_stop.add_var_box(\"output1\", 1.0, 2.5)\n",
    "set_point_stop.add_var_box(\"output2\", 1.2, 3.0)\n",
    "\n",
    "terminations = VarSpace(\"terminations\")\n",
    "\n",
    "config = FMUGymConfig(fmu_path=os.path.abspath('FMUs/dummy_for_FMU_cosim.fmu'),\n",
    "                      start_time=0.0,\n",
    "                      stop_time=10.0,\n",
    "                      sim_step_size=0.01,\n",
    "                      action_step_size=0.01,\n",
    "                      inputs=inputs,\n",
    "                      input_noise=input_noise,\n",
    "                      outputs=outputs,\n",
    "                      output_noise=output_noise,\n",
    "                      random_vars=random_vars,\n",
    "                      set_point_map=set_point_map,\n",
    "                      set_point_nominal_start=set_point_nominal_start,\n",
    "                      set_point_stop=set_point_stop,\n",
    "                      terminations=terminations\n",
    "                     )\n",
    "\n",
    "config.disc_resol_act = 0.1\n",
    "config.disc_resol_obs = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82741f5-2bd4-45dc-966e-3083f2cb13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = read_model_description(config.fmu_path)\n",
    "print(model_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe83cf",
   "metadata": {},
   "source": [
    "### Creation of gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baf88f-91cb-481b-9e96-0c6808ca36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyEnv = FMUEnv(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143def4d",
   "metadata": {},
   "source": [
    "### Learning of SB3 agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(\n",
    "    \"MultiInputPolicy\",\n",
    "    dummyEnv,\n",
    "    gamma=1.00,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timer_start_time = time.time()\n",
    "model.learn(total_timesteps=3e5)\n",
    "print(\"learn duration: \", time.time() - timer_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4852fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_agents/a2c_discrete_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a95826",
   "metadata": {},
   "source": [
    "### ... or loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C.load(\"trained_agents/a2c_discrete_agent.zip\", dummyEnv, print_system_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615fb30",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c66bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = dummyEnv.reset()\n",
    "obs_array = []\n",
    "act_array = []\n",
    "obs_array.append(observation[\"observation\"])\n",
    "\n",
    "num_steps = int((config.stop_time - config.start_time) / config.sim_step_size)\n",
    "for _ in range(num_steps):\n",
    "    action, _state = model.predict(observation, deterministic=True)\n",
    "    observation, reward, terminated, truncated, info = dummyEnv.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = dummyEnv.reset()\n",
    "    obs_array.append(observation[\"observation\"])\n",
    "    act_array.append(dummyEnv.processed_action)\n",
    "\n",
    "obs_array = np.array(obs_array).flatten()\n",
    "obs_array = obs_array.reshape(-1, 2)  \n",
    "act_array = np.array(act_array).flatten()\n",
    "act_array = act_array.reshape(-1, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42713211-7a10-4222-88cb-ec8db733f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_setpoints = []\n",
    "y2_setpoints = []\n",
    "\n",
    "for t in np.arange(config.start_time, config.stop_time, config.sim_step_size):\n",
    "    y1_setpoints.append(dummyEnv.setpoint_trajectory(dummyEnv.y_start, dummyEnv.y_stop, t)[0])\n",
    "    y2_setpoints.append(dummyEnv.setpoint_trajectory(dummyEnv.y_start, dummyEnv.y_stop, t)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(obs_array[:, 0], label='y1', color=\"b\")\n",
    "plt.plot(y1_setpoints, label='y1_set', color=\"b\", linestyle='--')\n",
    "plt.plot(obs_array[:, 1], label='y2', color=\"r\")\n",
    "plt.plot(y2_setpoints, label='y2_set', color=\"r\", linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(act_array[:, 0], label='u1', color=\"b\")\n",
    "plt.plot(act_array[:, 1], label='u2', color=\"r\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyEnv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ba3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
