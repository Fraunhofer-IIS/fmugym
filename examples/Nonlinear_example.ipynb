{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225772d6",
   "metadata": {},
   "source": [
    "# Nonlinear example for gym environment with FMU with HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11deb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from fmpy import read_model_description, extract\n",
    "\n",
    "from fmugym import FMUGym, FMUGymConfig, VarSpace, State2Out, TargetValue\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC, HerReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093d19b1",
   "metadata": {},
   "source": [
    "### Parameters of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4042a3b-5935-4fc3-999f-d6646b7d7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMUEnv(FMUGym):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {'info_time':time.time()}\n",
    "\n",
    "    # possibility to do processing of FMU outputs to observations of the environment here\n",
    "    def _get_obs(self):\n",
    "        \n",
    "        self._get_fmu_output()\n",
    "\n",
    "        obs = np.array(list(self.observation.values())).flatten()\n",
    "        \n",
    "        noisy_observation = obs + self._get_output_noise()\n",
    "        \n",
    "        setpoint = self.setpoint_trajectory(self.y_start, self.y_stop, self.time)\n",
    "\n",
    "        obs_dict = OrderedDict([\n",
    "            ('observation', np.array(noisy_observation)),\n",
    "            ('achieved_goal', np.array(noisy_observation)),\n",
    "            ('desired_goal', setpoint.astype(np.float32))\n",
    "        ])\n",
    "        return obs_dict\n",
    "    \n",
    "    def _get_input_noise(self):\n",
    "        input_noise = []\n",
    "        for inp_name in self.input_dict:\n",
    "            input_noise.append(self.input_noise[inp_name].sample()[0])\n",
    "        return np.array(input_noise)\n",
    "\n",
    "    def _get_output_noise(self):\n",
    "        output_noise = []\n",
    "        for out_name in self.output_dict:\n",
    "                output_noise.append(self.output_noise[out_name].sample()[0])\n",
    "        return np.array(output_noise)\n",
    "\n",
    "    def _get_terminated(self):\n",
    "        if self.time > self.stop_time:\n",
    "            self.reset()\n",
    "            return True, False\n",
    "\n",
    "        for termination in self.terminations:\n",
    "            min_value = self.terminations[termination].low[0]\n",
    "            max_value = self.terminations[termination].high[0]\n",
    "            if self.observation[termination] < min_value or self.observation[termination] > max_value:\n",
    "                self.reset()\n",
    "                return False, True\n",
    "\n",
    "        return False, False\n",
    "\n",
    "    def _create_action_space(self, inputs):\n",
    "        lows = []\n",
    "        highs = []\n",
    "        for inp in inputs:\n",
    "            lows.append(inputs[inp].low[0])\n",
    "            highs.append(inputs[inp].high[0])\n",
    "        action_space = gym.spaces.Box(low=np.array(lows), high=np.array(highs), dtype=np.float32)\n",
    "        return action_space\n",
    "    \n",
    "    def _create_observation_space(self, outputs):\n",
    "        lows = []\n",
    "        highs = []\n",
    "        for out in outputs:\n",
    "            lows.append(outputs[out].low[0])\n",
    "            highs.append(outputs[out].high[0])\n",
    "        observation_space = gym.spaces.Dict({\n",
    "            'observation': gym.spaces.Box(low=np.array(lows), high=np.array(highs), dtype=np.float32),\n",
    "            'achieved_goal': gym.spaces.Box(low=np.array(lows), high=np.array(highs), dtype=np.float32),\n",
    "            'desired_goal': gym.spaces.Box(low=np.array(lows), high=np.array(highs), dtype=np.float32)\n",
    "        })\n",
    "        return observation_space\n",
    "\n",
    "    def _noisy_init(self):\n",
    "        # add noise to setpoint goals\n",
    "        for ye in self.y_stop:\n",
    "            self.y_stop[ye] = self.y_stop_range[ye].sample()[0]\n",
    "        \n",
    "        # add noise to initial system state\n",
    "        init_states = {}\n",
    "        for var in self.random_vars_refs:\n",
    "            var_ref = self.random_vars_refs[var][0]\n",
    "            uniform_value = self.random_vars_refs[var][1].sample()[0]\n",
    "            init_states[var_ref] = uniform_value\n",
    "\n",
    "            # domain randomization with noisy initial y_start\n",
    "            if var in self.rand_starts.keys():\n",
    "                input_string = self.rand_starts[var]\n",
    "                self.y_start[input_string] = float(uniform_value)\n",
    "        \n",
    "        return init_states\n",
    "\n",
    "    def _process_action(self, action):\n",
    "        processed_action = action + self._get_input_noise()\n",
    "        return processed_action\n",
    "\n",
    "    def setpoint_trajectory(self, y_start, y_stop, time):\n",
    "        y = []\n",
    "        for y0, ye in zip(y_start.values(), y_stop.values()):\n",
    "            y.append((ye - y0)/(self.stop_time-self.start_time)*(time-self.start_time) + y0)\n",
    "        return np.array(y)\n",
    "\n",
    "    def _process_reward(self, obs, acts, info):\n",
    "        achieved_goal = obs[\"achieved_goal\"]\n",
    "        desired_goal = obs[\"desired_goal\"]\n",
    "        reward = self.compute_reward(achieved_goal, desired_goal, info)\n",
    "        return reward\n",
    "\n",
    "    \n",
    "    def compute_reward(self, achieved_goal, desired_goal, info):\n",
    "        \"\"\"\n",
    "        compute reward for HER\n",
    "            achieved_goal: outputs of FMU\n",
    "            desired_goal: current setpoint of trajectory\n",
    "            info: [NOT USED]\n",
    "        Returns:\n",
    "            float: environment reward\n",
    "        \"\"\"\n",
    "\n",
    "        # Deceptive reward: it is positive (0) only when the goal is achieved\n",
    "        # Here we are using a vectorized version\n",
    "        boundary_accuracy = 0.1\n",
    "        control_error = achieved_goal - desired_goal\n",
    "        if len(control_error) == self.observation_space[\"observation\"].shape[0]:\n",
    "                boundary_violated = False\n",
    "                for err in control_error:\n",
    "                    boundary_violated = boundary_violated or (abs(err)>boundary_accuracy)            \n",
    "                reward = -(boundary_violated.astype(np.float32))\n",
    "                \n",
    "        else:\n",
    "            reward = []\n",
    "            for ctrl_err in control_error:\n",
    "                boundary_violated = False\n",
    "                for err in ctrl_err:\n",
    "                    boundary_violated = boundary_violated or (abs(err)>boundary_accuracy)\n",
    "                reward.append(-(boundary_violated.astype(np.float32)))\n",
    "        \n",
    "        return np.array(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0c104-e5d3-4659-b2a2-d8ef1eaab83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = VarSpace(\"inputs\")\n",
    "inputs.add_var_box(\"input1\", -10.0, 10.0)\n",
    "inputs.add_var_box(\"input2\", -10.0, 10.0)\n",
    "\n",
    "input_noise = VarSpace(\"input_noise\")\n",
    "input_noise.add_var_box(\"input1\", -5.0, 5.0)\n",
    "input_noise.add_var_box(\"input2\", -5.0, 5.0)\n",
    "\n",
    "outputs = VarSpace(\"outputs\")\n",
    "outputs.add_var_box(\"output1\", -1e6, 1e6)\n",
    "outputs.add_var_box(\"output2\", -1e6, 1e6)\n",
    "\n",
    "output_noise = VarSpace(\"output_noise\")\n",
    "output_noise.add_var_box(\"output1\", -0.05, 0.05)\n",
    "output_noise.add_var_box(\"output2\", -0.05, 0.05)\n",
    "\n",
    "# dynamics and domain randomization\n",
    "random_vars = VarSpace(\"random_vars\")\n",
    "random_vars.add_var_box(\"firstOrder.k\", 4, 6)\n",
    "random_vars.add_var_box(\"firstOrder1.k\", 4, 6)\n",
    "random_vars.add_var_box(\"firstOrder.y_start\", -0.5, 0.5)\n",
    "random_vars.add_var_box(\"firstOrder1.y_start\", -0.5, 0.5)\n",
    "\n",
    "# map state variables to corresponding outputs of Modelica Model for init values\n",
    "set_point_map = State2Out(\"set_point_map\")\n",
    "set_point_map.add_map(\"firstOrder.y_start\", \"output1\")\n",
    "set_point_map.add_map(\"firstOrder1.y_start\", \"output2\")\n",
    "\n",
    "set_point_nominal_start = TargetValue(\"set_point_nominal_start\")\n",
    "set_point_nominal_start.add_target(\"output1\", 0.0)\n",
    "set_point_nominal_start.add_target(\"output2\", 0.0)\n",
    "\n",
    "set_point_stop = VarSpace(\"set_point_stop\")\n",
    "set_point_stop.add_var_box(\"output1\", 1.0, 2.5)\n",
    "set_point_stop.add_var_box(\"output2\", 1.2, 3.0)\n",
    "\n",
    "terminations = VarSpace(\"terminations\")\n",
    "\n",
    "config = FMUGymConfig(fmu_path=os.path.abspath('FMUs/NonlinearMIMO.fmu'),\n",
    "                      start_time=0.0,\n",
    "                      stop_time=10.0,\n",
    "                      sim_step_size=0.01,\n",
    "                      action_step_size=0.01,\n",
    "                      inputs=inputs,\n",
    "                      input_noise=input_noise,\n",
    "                      outputs=outputs,\n",
    "                      output_noise=output_noise,\n",
    "                      random_vars=random_vars,\n",
    "                      set_point_map=set_point_map,\n",
    "                      set_point_nominal_start=set_point_nominal_start,\n",
    "                      set_point_stop=set_point_stop,\n",
    "                      terminations=terminations\n",
    "                     )                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82741f5-2bd4-45dc-966e-3083f2cb13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = read_model_description(config.fmu_path)\n",
    "print(model_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe83cf",
   "metadata": {},
   "source": [
    "### Creation of gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baf88f-91cb-481b-9e96-0c6808ca36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyEnv = FMUEnv(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143def4d",
   "metadata": {},
   "source": [
    "### Learning of SB3 agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC(\n",
    "    \"MultiInputPolicy\",\n",
    "    dummyEnv,\n",
    "    replay_buffer_class=HerReplayBuffer,\n",
    "    replay_buffer_kwargs=dict(\n",
    "        n_sampled_goal=6,\n",
    "        goal_selection_strategy=\"future\",\n",
    "    ),\n",
    "    ent_coef=\"auto_1.0\",\n",
    "    learning_starts = int(2*(config.stop_time - config.start_time)/config.sim_step_size),\n",
    "    gamma=0.99,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8ba69-454c-4383-b165-c53359c43e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyEnv.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timer_start_time = time.time()\n",
    "model.learn(total_timesteps=3e5)\n",
    "print(\"learn duration: \", time.time() - timer_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4852fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_agents/sac_agent_nonlinear_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a95826",
   "metadata": {},
   "source": [
    "### ... or loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC.load(\"trained_agents/sac_agent_nonlinear_example.zip\", dummyEnv, print_system_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615fb30",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c66bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = dummyEnv.reset()\n",
    "obs_array = []\n",
    "act_array = []\n",
    "obs_array.append(observation[\"observation\"])\n",
    "\n",
    "num_steps = int((config.stop_time - config.start_time) / config.sim_step_size)\n",
    "for _ in range(num_steps):\n",
    "    action, _state = model.predict(observation, deterministic=True) \n",
    "    observation, reward, terminated, truncated, info = dummyEnv.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = dummyEnv.reset()\n",
    "    obs_array.append(observation[\"observation\"])\n",
    "    act_array.append(action)\n",
    "\n",
    "obs_array = np.array(obs_array).flatten()\n",
    "obs_array = obs_array.reshape(-1, 2)  \n",
    "act_array = np.array(act_array).flatten()\n",
    "act_array = act_array.reshape(-1, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872eadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_setpoints = []\n",
    "y2_setpoints = []\n",
    "\n",
    "for t in np.arange(config.start_time, config.stop_time, config.sim_step_size):\n",
    "    y1_setpoints.append(dummyEnv.setpoint_trajectory(dummyEnv.y_start, dummyEnv.y_stop, t)[0])\n",
    "    y2_setpoints.append(dummyEnv.setpoint_trajectory(dummyEnv.y_start, dummyEnv.y_stop, t)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(obs_array[:, 0], label='y1', color=\"b\")\n",
    "plt.plot(y1_setpoints, label='y1_set', color=\"b\", linestyle='--')\n",
    "plt.plot(obs_array[:, 1], label='y2', color=\"r\")\n",
    "plt.plot(y2_setpoints, label='y2_set', color=\"r\", linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(act_array[:, 0], label='u1', color=\"b\")\n",
    "plt.plot(act_array[:, 1], label='u2', color=\"r\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyEnv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42dc4ba-ae2c-4d6a-b981-44ed65f8989a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
